{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-10T20:11:26.100579Z",
     "iopub.status.busy": "2025-08-10T20:11:26.100371Z",
     "iopub.status.idle": "2025-08-10T20:11:26.107627Z",
     "shell.execute_reply": "2025-08-10T20:11:26.106890Z",
     "shell.execute_reply.started": "2025-08-10T20:11:26.100559Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTALLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:11:26.109700Z",
     "iopub.status.busy": "2025-08-10T20:11:26.109429Z",
     "iopub.status.idle": "2025-08-10T20:12:52.874685Z",
     "shell.execute_reply": "2025-08-10T20:12:52.873613Z",
     "shell.execute_reply.started": "2025-08-10T20:11:26.109681Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:12:52.876395Z",
     "iopub.status.busy": "2025-08-10T20:12:52.876089Z",
     "iopub.status.idle": "2025-08-10T20:13:55.557276Z",
     "shell.execute_reply": "2025-08-10T20:13:55.556334Z",
     "shell.execute_reply.started": "2025-08-10T20:12:52.876364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/KaiyangZhou/deep-person-reid.git\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:13:55.558924Z",
     "iopub.status.busy": "2025-08-10T20:13:55.558541Z",
     "iopub.status.idle": "2025-08-10T20:13:59.799242Z",
     "shell.execute_reply": "2025-08-10T20:13:59.798348Z",
     "shell.execute_reply.started": "2025-08-10T20:13:55.558883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install deep-sort-realtime\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: most of the comments were genreated using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:15:40.580008Z",
     "iopub.status.busy": "2025-08-10T20:15:40.579088Z",
     "iopub.status.idle": "2025-08-10T20:15:49.005298Z",
     "shell.execute_reply": "2025-08-10T20:15:49.004496Z",
     "shell.execute_reply.started": "2025-08-10T20:15:40.579952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Core Computer Vision Libraries ---\n",
    "from ultralytics import YOLO  # YOLO for object detection\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort # DeepSORT for initial tracking\n",
    "import cv2 # OpenCV for video and image processing\n",
    "\n",
    "# --- Re-identification and Feature Handling ---\n",
    "import torchreid # Used by DeepSORT to extract appearance features\n",
    "from torchreid.utils import FeatureExtractor\n",
    "from scipy.spatial.distance import cosine # To calculate similarity between feature vectors\n",
    "\n",
    "# --- Utility and System Libraries ---\n",
    "from tqdm import tqdm # For creating progress bars\n",
    "import numpy as np # For numerical operations (coordinates, heatmaps)\n",
    "import torch # PyTorch, underlying framework for YOLO and torchreid\n",
    "import os # For interacting with the operating system (e.g., file paths)\n",
    "import glob # For finding files matching a specific pattern\n",
    "import csv # For writing analysis results to CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:16:01.041690Z",
     "iopub.status.busy": "2025-08-10T20:16:01.040713Z",
     "iopub.status.idle": "2025-08-10T20:16:01.049101Z",
     "shell.execute_reply": "2025-08-10T20:16:01.048166Z",
     "shell.execute_reply.started": "2025-08-10T20:16:01.041663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# MAIN TRACKER USING DEEPSORT\n",
    "class Tracker:\n",
    "    def __init__(self):\n",
    "    \n",
    "         # Initialize the DeepSort tracker object\n",
    "         self.object_tracker = DeepSort(\n",
    "            max_age=150,           # Max number of frames to keep a track alive without new detections.\n",
    "            n_init=3,              # Min number of consecutive detections to start a new track.\n",
    "            nms_max_overlap=0.7,   # NMS threshold to avoid overlapping tracks.\n",
    "            max_cosine_distance=0.4, # Max appearance distance. A larger value allows re-associating less similar looking objects.\n",
    "            nn_budget=100,         # Size of the appearance feature gallery for each track.\n",
    "            override_track_class=None,\n",
    "            embedder=\"torchreid\",  # Use the torchreid library for feature extraction.\n",
    "            half=True,             \n",
    "            bgr=False,             \n",
    "            embedder_model_name='osnet_x1_0', # The specific re-identification model to use.\n",
    "            \n",
    "            embedder_wts='osnet_x1_0_market_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip.pth',\n",
    "            polygon=False,\n",
    "            today=None,\n",
    "         )\n",
    "         \n",
    "    def track(self, detections, frame):\n",
    "        \"\"\"\n",
    "        Updates the tracker with new detections for the current frame.\n",
    "        \n",
    "        Args:\n",
    "            detections: A list of detections from the YOLO model.\n",
    "            frame: The current video frame.\n",
    "            \n",
    "        Returns:\n",
    "            A list of valid, confirmed tracks.\n",
    "        \"\"\"\n",
    "        # Pass the detections and frame to the DeepSORT update method\n",
    "        tracks = self.object_tracker.update_tracks(detections, frame=frame)\n",
    "\n",
    "        valid_tracks = []\n",
    "        # Filter out tracks that are not yet confirmed or have been lost\n",
    "        for track in tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 0:\n",
    "                continue\n",
    "            \n",
    "            track_info = {\n",
    "                \"id\": track.track_id,         # The ID assigned by DeepSORT\n",
    "                \"box\": track.to_ltrb(),       # Bounding box in (left, top, right, bottom) format\n",
    "                \"feature\": track.features[-1], # The latest appearance feature vector\n",
    "                \"class\": track.get_det_class(), # The object's class name (e.g., 'person')\n",
    "                \"conf\": track.get_det_conf()      # The detection confidence score\n",
    "            }\n",
    "            valid_tracks.append(track_info)\n",
    "            \n",
    "        return valid_tracks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:16:01.451676Z",
     "iopub.status.busy": "2025-08-10T20:16:01.451067Z",
     "iopub.status.idle": "2025-08-10T20:16:01.468159Z",
     "shell.execute_reply": "2025-08-10T20:16:01.467275Z",
     "shell.execute_reply.started": "2025-08-10T20:16:01.451652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PostTracker:\n",
    "     \"\"\"\n",
    "    A robust post-processing tracker to handle ID re-association and prevent ID switching.\n",
    "    DeepSORT can sometimes recycle IDs, causing a new person to get an old ID.\n",
    "    This class maintains a permanent 'original_id' for each person, even if their\n",
    "    DeepSORT ID changes after they are lost and re-detected.\n",
    "    \"\"\"\n",
    "    def __init__(self, similarity_threshold=0.65, max_dist_from_last_seen=150, time_threshold=45,\n",
    "                 motion_lambda=0.3, max_cost_threshold=0.6, feature_history_size=10, debug=False):\n",
    "        \n",
    "        # --- Parameters ---\n",
    "        self.similarity_threshold = similarity_threshold # Min appearance similarity (1-cosine_distance) to be considered a match.\n",
    "        self.spatial_threshold = max_dist_from_last_seen # Max pixel distance to search for a lost track.\n",
    "        self.time_threshold = time_threshold             # Max frames a track can be 'lost' before being discarded.\n",
    "        self.motion_lambda = motion_lambda               # Weight for spatial distance in the cost function (0.0 to 1.0). (1 - motion_lambda) is the weight for appearance.\n",
    "        self.max_cost_threshold = max_cost_threshold     # The maximum combined cost for a re-association to be considered valid.\n",
    "        self.feature_history_size = feature_history_size # Number of recent appearance features to store for each track.\n",
    "        self.debug = debug                               # Flag to print debugging information.\n",
    "\n",
    "        # --- State Tracking Dictionaries ---\n",
    "        self.track_map = {}            # Maps current DeepSORT ID -> permanent Original ID {deepsort_id: original_id}\n",
    "        self.active_tracks = {}        # Stores data for currently visible tracks {original_id: data}\n",
    "        self.lost_tracks = {}          # Stores data for tracks that are temporarily lost {original_id: data}\n",
    "        self.next_original_id = 1      # Counter for assigning new permanent IDs.\n",
    "\n",
    "    def _get_centroid(self, box):\n",
    "        # calc the center of the box\n",
    "        return (int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2))\n",
    "\n",
    "    def _get_new_original_id(self):\n",
    "        # Increments and returns a new unique ID for a person.\n",
    "        new_id = self.next_original_id\n",
    "        self.next_original_id += 1\n",
    "        return new_id\n",
    "\n",
    "    def update(self, current_frame_tracks, frame_number):\n",
    "        # Get the set of all DeepSORT IDs visible in the current frame\n",
    "        current_deepsort_ids = {t['id'] for t in current_frame_tracks}\n",
    "\n",
    "        # 1. Identify tracks that were active but are now lost.\n",
    "        lost_original_ids = {oid for oid, data in self.active_tracks.items() if data['deepsort_id'] not in current_deepsort_ids}\n",
    "        for original_id in lost_original_ids:\n",
    "            lost_data = self.active_tracks[original_id]\n",
    "            avg_feature = np.mean(lost_data['features'], axis=0)\n",
    "            self.lost_tracks[original_id] = {'box': lost_data['box'], 'feature': avg_feature, 'frame_lost': frame_number}\n",
    "            \n",
    "            # IMPORTANT: Forget the DeepSORT ID mapping. This prevents a new person who might\n",
    "            # get this recycled DeepSORT ID from being incorrectly mapped to the old original ID.\n",
    "            deepsort_id_to_forget = lost_data['deepsort_id']\n",
    "            if deepsort_id_to_forget in self.track_map:\n",
    "                del self.track_map[deepsort_id_to_forget]\n",
    "            \n",
    "            del self.active_tracks[original_id]\n",
    "            if self.debug: print(f\"-Frame {frame_number}: Moved Original ID {original_id} to LOST list\")\n",
    "\n",
    "        # 2. Process currently visible tracks\n",
    "        for track in current_frame_tracks:\n",
    "            deepsort_id = track['id']\n",
    "            mapped_id = self.track_map.get(deepsort_id)\n",
    "\n",
    "            # Case A: This DeepSORT ID is already mapped to an active original ID (continuous tracking).\n",
    "            if mapped_id is not None: \n",
    "                self.active_tracks[mapped_id]['box'] = track['box']\n",
    "                self.active_tracks[mapped_id]['features'].append(track['feature'])\n",
    "                if len(self.active_tracks[mapped_id]['features']) > self.feature_history_size:\n",
    "                    self.active_tracks[mapped_id]['features'].pop(0)\n",
    "\n",
    "            # Case B: This is a \"newcomer\" - either a truly new person or a re-appearing lost person.\n",
    "            else: \n",
    "                best_match_id = None\n",
    "                min_cost = float('inf')\n",
    "                # Try to match this newcomer with tracks in the 'lost' list.\n",
    "                for lost_id, lost_data in list(self.lost_tracks.items()):\n",
    "                    if frame_number - lost_data['frame_lost'] > self.time_threshold:\n",
    "                        del self.lost_tracks[lost_id]\n",
    "                        continue\n",
    "\n",
    "                    spatial_dist = np.linalg.norm(np.array(self._get_centroid(track['box'])) - np.array(self._get_centroid(lost_data['box'])))\n",
    "                    if spatial_dist > self.spatial_threshold: continue\n",
    "\n",
    "                    similarity = 1 - cosine(track['feature'], lost_data['feature'])\n",
    "                    if similarity < self.similarity_threshold: continue\n",
    "\n",
    "                    # --- Weighted Cost Function ---\n",
    "                    # Combine appearance and motion cues into a single cost. Lower is better.\n",
    "                    appearance_cost = 1 - similarity\n",
    "                    appearance_cost = 1 - similarity\n",
    "                    spatial_cost = spatial_dist / self.spatial_threshold\n",
    "                    combined_cost = ((1 - self.motion_lambda) * appearance_cost) + (self.motion_lambda * spatial_cost)\n",
    "\n",
    "                    if self.debug:\n",
    "                        print(f\"-Frame {frame_number}: Checking New DS_ID {deepsort_id} against Lost Original_ID {lost_id}-\")\n",
    "                        print(f\"-Cost Components: Appearance={appearance_cost:.3f}, Spatial={spatial_cost:.3f}\")\n",
    "                        print(f\"-Combined Cost: {combined_cost:.4f} (lower is better)\")\n",
    "\n",
    "                    # If this is the best match so far, save it.\n",
    "                    if combined_cost < min_cost:\n",
    "                        min_cost = combined_cost\n",
    "                        best_match_id = lost_id\n",
    "                        \n",
    "                # If a suitable match was found in the lost list... Re-associate the track.\n",
    "                if best_match_id is not None and min_cost < self.max_cost_threshold:\n",
    "                    original_id = best_match_id\n",
    "                    self.track_map[deepsort_id] = original_id # Create new mapping\n",
    "                    self.active_tracks[original_id] = {\n",
    "                        'box': track['box'], 'features': [track['feature']], 'deepsort_id': deepsort_id,\n",
    "                        'class': track['class'], 'conf': track['conf']\n",
    "                    }\n",
    "                    del self.lost_tracks[original_id]\n",
    "                    if self.debug: print(f\"=>RE-ASSOCIATED: New DS_ID {deepsort_id} -> OriginalID {original_id} (Cost: {min_cost:.4f})\")\n",
    "                        \n",
    "                # If no suitable match was found, this is a truly new person.\n",
    "                else:\n",
    "                    original_id = self._get_new_original_id()\n",
    "                    self.track_map[deepsort_id] = original_id # Create new mapping\n",
    "                    self.active_tracks[original_id] = {\n",
    "                        'box': track['box'], 'features': [track['feature']], 'deepsort_id': deepsort_id,\n",
    "                        'class': track['class'], 'conf': track['conf']\n",
    "                    }\n",
    "                    if self.debug: print(f\"=>NEW PERSON: New DS_ID {deepsort_id} -> New OriginalID {original_id}\")\n",
    "\n",
    "    def get_active_tracks(self):\n",
    "        # Returns a clean list of currently active tracks with their permanent original IDs.\n",
    "        final_tracks = []\n",
    "        for original_id, data in self.active_tracks.items():\n",
    "            final_tracks.append({\n",
    "                \"id\": original_id, \"box\": data['box'],\n",
    "                \"class\": data.get('class', 'Person'), \"conf\": data.get('conf', 0)\n",
    "            })\n",
    "        return final_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:16:01.748014Z",
     "iopub.status.busy": "2025-08-10T20:16:01.747375Z",
     "iopub.status.idle": "2025-08-10T20:16:01.755301Z",
     "shell.execute_reply": "2025-08-10T20:16:01.754534Z",
     "shell.execute_reply.started": "2025-08-10T20:16:01.747984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# MAIN YOLO DETECTOR CUSTOMIZED FOR DEEPSORT\n",
    "# A wrapper class for the YOLO object detector, customized for DeepSORT integration.\n",
    "class YoloDetector:\n",
    "    def __init__(self, model, confidence, target_classes = None):\n",
    "        self.model = YOLO(model).to('cuda')\n",
    "        self.confidence = confidence\n",
    "        self.target_classes = target_classes\n",
    "\n",
    "    def detect(self, image):\n",
    "        # run yolo and get detections\n",
    "        results = self.model.predict(image, conf = self.confidence, classes = self.target_classes, verbose=False, iou=0.45)\n",
    "        result = results[0]\n",
    "        names = result.names\n",
    "        detections, labels, confidences = self.conver_detections(result, names)\n",
    "        return detections, labels, confidences\n",
    "    \n",
    "    def conver_detections(self, result, names):\n",
    "        \"\"\"\n",
    "        Converts YOLO's output format to the DeepSORT required format.\n",
    "        DeepSORT requires: (([left, top, width, height]), confidence, class_name)\n",
    "        \"\"\"\n",
    "        \n",
    "        boxes = result.boxes\n",
    "        detections = []\n",
    "        labels = []\n",
    "        confidences = []\n",
    "        for box in boxes:\n",
    "\n",
    "            # Convert to (left, top, width, height) format.\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            \n",
    "            class_number = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            class_name = names[class_number]\n",
    "            detections.append((([x1, y1, w, h]),conf, class_name))\n",
    "            labels.append(class_name)\n",
    "            confidences.append(conf)\n",
    "            \n",
    "        return detections, labels, confidences\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HeatMap Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:16:02.019943Z",
     "iopub.status.busy": "2025-08-10T20:16:02.019096Z",
     "iopub.status.idle": "2025-08-10T20:16:02.030333Z",
     "shell.execute_reply": "2025-08-10T20:16:02.029448Z",
     "shell.execute_reply.started": "2025-08-10T20:16:02.019912Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class HeatmapGenerator:\n",
    "    \"\"\"\n",
    "    Generates and overlays a heatmap based on bounding box locations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h, w, decay_factor=0.97, colormap=cv2.COLORMAP_JET):\n",
    "\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        self.decay_factor = decay_factor # Rate at which heat fades. 1.0 = no decay, 0.9 = fast decay.\n",
    "        self.colormap = colormap\n",
    "        self.heatmap = np.zeros((h, w), dtype=np.float32) # A heatmap that decays over time, showing recent activity.           \n",
    "        self.cumulative_heatmap = np.zeros((h, w), dtype=np.float32) # A heatmap that accumulates all activity over the entire video. \n",
    "\n",
    "    def _add_heat(self, box):\n",
    "        x0, y0, x1, y1 = map(int, box)\n",
    "    \n",
    "        # Clamp box to valid heatmap boundaries (this is to ensure that the cordinates inside the frame boundries )\n",
    "        x0 = max(0, min(x0, self.w - 1))\n",
    "        x1 = max(0, min(x1, self.w))\n",
    "        y0 = max(0, min(y0, self.h - 1))\n",
    "        y1 = max(0, min(y1, self.h))\n",
    "    \n",
    "        if x1 <= x0 or y1 <= y0:\n",
    "            return\n",
    "    \n",
    "        radius = int(min(x1 - x0, y1 - y0) * 0.25)\n",
    "        if radius <= 0:\n",
    "            return\n",
    "        radius_squared = radius ** 2\n",
    "    \n",
    "        # Meshgrid over the ROI\n",
    "        # Center the heat spot at the bottom-center of the box (approximates foot position).\n",
    "        xv, yv = np.meshgrid(np.arange(x0, x1), np.arange(y0, y1))\n",
    "        center_x = (x0 + x1) // 2\n",
    "        center_y = max(y0, y1 - 15)  # foot level\n",
    "    \n",
    "        dist_squared = (xv - center_x) ** 2 + (yv - center_y) ** 2\n",
    "    \n",
    "        # Gaussian-like heat\n",
    "        heat = np.exp(-dist_squared / (2 * radius_squared))\n",
    "    \n",
    "        heat_patch = heat.astype(np.float32)\n",
    "        \n",
    "        # Update decaying heatmap\n",
    "        roi_live = self.heatmap[y0:y1, x0:x1]\n",
    "        roi_live += heat_patch\n",
    "        self.heatmap[y0:y1, x0:x1] = roi_live\n",
    "        \n",
    "        # Update cumulative heatmap\n",
    "        roi_cum = self.cumulative_heatmap[y0:y1, x0:x1]\n",
    "        roi_cum += heat_patch\n",
    "        self.cumulative_heatmap[y0:y1, x0:x1] = roi_cum\n",
    "\n",
    "    def update(self, boxes):\n",
    "\n",
    "        # 1. Apply decay to the entire heatmap\n",
    "        self.heatmap *= self.decay_factor\n",
    "\n",
    "        # 2. Add new heat for each bounding box\n",
    "        for box in boxes:\n",
    "            self._add_heat(box)\n",
    "\n",
    "    def generate(self, frame):\n",
    "\n",
    "        # Normalize the heatmap to the 0-255 range\n",
    "        normalized_heatmap = cv2.normalize(self.heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        colored_heatmap = normalized_heatmap.astype(np.uint8)\n",
    "\n",
    "        # Apply the colormap\n",
    "        colored_heatmap = cv2.applyColorMap(colored_heatmap, self.colormap)\n",
    "\n",
    "        # Blend the heatmap with the original frame\n",
    "        final_frame = cv2.addWeighted(frame, 0.6, colored_heatmap, 0.4, 0)\n",
    "\n",
    "        return final_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T21:14:02.271855Z",
     "iopub.status.busy": "2025-08-10T21:14:02.270946Z",
     "iopub.status.idle": "2025-08-10T21:14:02.289763Z",
     "shell.execute_reply": "2025-08-10T21:14:02.288813Z",
     "shell.execute_reply.started": "2025-08-10T21:14:02.271823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CountingSystem:\n",
    "    \"\"\"\n",
    "    Manages counting, dwell time calculation, and visitor behavior analysis (dwelled vs. passed-by)\n",
    "    for a specific polygonal area.\n",
    "    \"\"\"\n",
    "    def __init__(self, main_area, entrance_areas, label, position_index=0, dwell_time_seconds=3, fps=30, debug=False):\n",
    "        \"\"\"\n",
    "        Initializes the counting system for one area.\n",
    "        Args:\n",
    "            main_area: A numpy array of points defining the main counting zone.\n",
    "            entrance_areas: A list of numpy arrays, each defining an entrance zone.\n",
    "            label: A string name for this area (e.g., 'Track_1').\n",
    "            dwell_time_seconds: The minimum time in seconds a person must be in the main_area to be counted.\n",
    "            fps: The frames-per-second of the video.\n",
    "        \"\"\"\n",
    "        self.main_area = main_area\n",
    "        self.entrances = entrance_areas\n",
    "        self.label = label\n",
    "        self.fps = fps\n",
    "        self.debug = debug\n",
    "\n",
    "        # --- State Tracking for Counting & Behavior Analysis ---\n",
    "        self.counted_ids = set()            # Stores IDs that have been confirmed as \"dwelled\".\n",
    "        self.passed_by_ids = set()          # Stores IDs that entered but left before the dwell time threshold.\n",
    "        self.entered_entrance_ids = set()   # Stores IDs that have been seen in an entrance zone.\n",
    "        self.main_area_entries = set()      # Stores IDs that have been seen in the main area.\n",
    "        self.dwelling_candidates = {}       # {track_id: entry_frame} for people currently inside the main area.\n",
    "        self.person_count = 0               # The final count of people who dwelled.\n",
    "\n",
    "        # --- State Tracking for Dwell Time Calculation ---\n",
    "        self.entry_frames = {} # {track_id: frame_number} when a person enters the main area.\n",
    "        self.dwell_times = {}  # {track_id: total_frames_dwelled} cumulative dwell time.\n",
    "\n",
    "        # --- Parameters ---\n",
    "        self.dwell_time_frames = int(dwell_time_seconds * fps) # Convert dwell time from seconds to frames.\n",
    "        \n",
    "        # --- Display Settings ---\n",
    "        self.text_y_position = 70 + (position_index * 60) # Stagger display text for multiple counters.\n",
    "\n",
    "    def _get_centroid(self, bbox):\n",
    "        \"\"\"\n",
    "        Consistent centroid calculation for both counting and pass-by logic.\n",
    "        \"\"\"\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        middle_y = (y1 + y2) / 2\n",
    "        fraction = 0.1\n",
    "        count_y = middle_y + (y2 - middle_y) * fraction\n",
    "        return (int((x1 + x2) / 2), int(count_y))\n",
    "\n",
    "    def update(self, tracking_ids, boxes, frame_number, frame=None):\n",
    "        \"\"\"\n",
    "        Updates counter, dwell time tracking, and pass-by analysis.\n",
    "        \"\"\"\n",
    "        current_frame_ids = set(tracking_ids)\n",
    "        \n",
    "        # --- Process each visible track ---\n",
    "        for track_id, bbox in zip(tracking_ids, boxes):\n",
    "            centroid = self._get_centroid(bbox)\n",
    "\n",
    "            # Draw debug circle\n",
    "            if self.debug and frame is not None:\n",
    "                cv2.circle(frame, centroid, 4, (0, 255, 0), -1)\n",
    "\n",
    "            is_in_main = cv2.pointPolygonTest(self.main_area, centroid, False) >= 0\n",
    "            is_in_entrance = any(cv2.pointPolygonTest(entrance, centroid, False) >= 0 for entrance in self.entrances)\n",
    "\n",
    "            # Simple tracking for pass-by\n",
    "            if is_in_entrance:\n",
    "                self.entered_entrance_ids.add(track_id)\n",
    "            if is_in_main:\n",
    "                self.main_area_entries.add(track_id)\n",
    "\n",
    "        # --- Original Counting Logic ---\n",
    "        for track_id, bbox in zip(tracking_ids, boxes):\n",
    "            if track_id in self.counted_ids:\n",
    "                continue\n",
    "\n",
    "            centroid = self._get_centroid(bbox)\n",
    "            is_in_main = cv2.pointPolygonTest(self.main_area, centroid, False) >= 0\n",
    "            is_in_entrance = any(cv2.pointPolygonTest(entrance, centroid, False) >= 0 for entrance in self.entrances)\n",
    "\n",
    "            # Check if this person is eligible to be a dwelling candidate\n",
    "            if track_id not in self.dwelling_candidates:\n",
    "                is_eligible = False\n",
    "                \n",
    "                # Early frames - anyone in main area is eligible\n",
    "                if frame_number <= self.dwell_time_frames and is_in_main:\n",
    "                    is_eligible = True\n",
    "                else:\n",
    "                    # Later frames - must have come through entrance\n",
    "                    if track_id in self.entered_entrance_ids and is_in_main: \n",
    "                        is_eligible = True\n",
    "                \n",
    "                if is_eligible: \n",
    "                    self.dwelling_candidates[track_id] = frame_number\n",
    "\n",
    "            # Process dwelling candidates\n",
    "            if track_id in self.dwelling_candidates:\n",
    "                if not is_in_main:\n",
    "                    # Left main area before dwelling time was reached\n",
    "                    del self.dwelling_candidates[track_id]\n",
    "                else:\n",
    "                    # Check if they've dwelled long enough\n",
    "                    frames_in_main = frame_number - self.dwelling_candidates[track_id]\n",
    "                    if frames_in_main >= self.dwell_time_frames:\n",
    "                        self.person_count += 1\n",
    "                        self.counted_ids.add(track_id)\n",
    "                        del self.dwelling_candidates[track_id]\n",
    "        \n",
    "        # Clean up lost candidates\n",
    "        lost_candidates = set(self.dwelling_candidates.keys()) - current_frame_ids\n",
    "        for track_id in lost_candidates:\n",
    "            del self.dwelling_candidates[track_id]\n",
    "\n",
    "        # --- Original Dwell Time Calculation ---\n",
    "        for track_id, bbox in zip(tracking_ids, boxes):\n",
    "            centroid = self._get_centroid(bbox)\n",
    "            is_in_main = cv2.pointPolygonTest(self.main_area, centroid, False) >= 0\n",
    "\n",
    "            if is_in_main:\n",
    "                if track_id not in self.entry_frames:\n",
    "                    self.entry_frames[track_id] = frame_number\n",
    "            else:\n",
    "                if track_id in self.entry_frames:\n",
    "                    duration = frame_number - self.entry_frames[track_id]\n",
    "                    self.dwell_times[track_id] = self.dwell_times.get(track_id, 0) + duration\n",
    "                    del self.entry_frames[track_id]\n",
    "\n",
    "        # Process disappeared tracks for dwell time\n",
    "        lost_ids = set(self.entry_frames.keys()) - current_frame_ids\n",
    "        for track_id in lost_ids:\n",
    "            duration = frame_number - self.entry_frames[track_id]\n",
    "            self.dwell_times[track_id] = self.dwell_times.get(track_id, 0) + duration\n",
    "            del self.entry_frames[track_id]\n",
    "\n",
    "    def finalize_dwell_times(self, last_frame_number):\n",
    "        \"\"\"\n",
    "        Call this after the video loop to finalize analysis.\n",
    "        \"\"\"\n",
    "        # Original dwell time finalization\n",
    "        for track_id, entry_frame in self.entry_frames.items():\n",
    "            duration = last_frame_number - entry_frame\n",
    "            self.dwell_times[track_id] = self.dwell_times.get(track_id, 0) + duration\n",
    "        self.entry_frames.clear()\n",
    "\n",
    "        # Enhanced classification logic for dwelled vs passed-by\n",
    "        for track_id in self.main_area_entries:\n",
    "            if track_id in self.entered_entrance_ids:  # Only people who entered through entrance\n",
    "                # Check actual dwell time instead of relying only on original counting algorithm\n",
    "                total_dwell_frames = self.dwell_times.get(track_id, 0)\n",
    "                \n",
    "                if total_dwell_frames >= self.dwell_time_frames:\n",
    "                    # They dwelled long enough - classify as dwelled\n",
    "                    # (Add to counted_ids for analysis only, don't change person_count)\n",
    "                    if track_id not in self.counted_ids:\n",
    "                        self.counted_ids.add(track_id)\n",
    "                else:\n",
    "                    # They didn't dwell long enough - classify as passed by\n",
    "                    self.passed_by_ids.add(track_id)\n",
    "\n",
    "    def print_analysis(self):\n",
    "        \"\"\"\n",
    "        Print the analysis of dwelled vs passed-by people.\n",
    "        \"\"\"\n",
    "        # Remove any overlap (safety check)\n",
    "        self.passed_by_ids = self.passed_by_ids - self.counted_ids\n",
    "        \n",
    "        dwelled_count = len(self.counted_ids)\n",
    "        passed_by_count = len(self.passed_by_ids)\n",
    "        total_visitors = dwelled_count + passed_by_count\n",
    "        \n",
    "        print(f\"\\n=== ANALYSIS FOR {self.label} ===\")\n",
    "        print(f\"👥 Total Visitors: {total_visitors}\")\n",
    "        print(f\"🏠 Dwelled (stayed ≥{self.dwell_time_frames/self.fps:.1f}s): {dwelled_count} ({dwelled_count/total_visitors*100 if total_visitors > 0 else 0:.1f}%)\")\n",
    "        print(f\"🚶 Passed By (left <{self.dwell_time_frames/self.fps:.1f}s): {passed_by_count} ({passed_by_count/total_visitors*100 if total_visitors > 0 else 0:.1f}%)\")\n",
    "        \n",
    "        if self.debug:\n",
    "            print(f\"Dwelled IDs: {sorted(list(self.counted_ids))}\")\n",
    "            print(f\"Passed-by IDs: {sorted(list(self.passed_by_ids))}\")\n",
    "            print(f\"Entered entrance IDs: {sorted(list(self.entered_entrance_ids))}\")\n",
    "            print(f\"Main area entries: {sorted(list(self.main_area_entries))}\")\n",
    "\n",
    "    def save_to_csv(self, filename):\n",
    "        \"\"\"\n",
    "        Saves dwell times to CSV for people who stayed >= dwell_time_seconds.\n",
    "        \"\"\"\n",
    "        import csv\n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['track_id', 'dwell_time_seconds'])\n",
    "\n",
    "            for track_id, total_frames in self.dwell_times.items():\n",
    "                if total_frames >= self.dwell_time_frames:\n",
    "                    dwell_seconds = round(total_frames / self.fps, 2)\n",
    "                    writer.writerow([track_id, dwell_seconds])\n",
    "\n",
    "        print(f\"✅ Dwell times (>= {self.dwell_time_frames / self.fps} seconds) saved to {filename}\")\n",
    "\n",
    "    def save_analysis_to_csv(self, filename):\n",
    "        \"\"\"\n",
    "        Save the analysis (dwelled vs passed-by) to a CSV file.\n",
    "        \"\"\"\n",
    "        import csv\n",
    "        # Remove any overlap before saving\n",
    "        self.passed_by_ids = self.passed_by_ids - self.counted_ids\n",
    "        \n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(['area', 'category', 'count', 'percentage'])\n",
    "            \n",
    "            dwelled_count = len(self.counted_ids)\n",
    "            passed_by_count = len(self.passed_by_ids)\n",
    "            total_visitors = dwelled_count + passed_by_count\n",
    "            \n",
    "            if total_visitors > 0:\n",
    "                dwelled_pct = round(dwelled_count / total_visitors * 100, 1)\n",
    "                passed_by_pct = round(passed_by_count / total_visitors * 100, 1)\n",
    "            else:\n",
    "                dwelled_pct = passed_by_pct = 0\n",
    "                \n",
    "            writer.writerow([self.label, 'Dwelled', dwelled_count, dwelled_pct])\n",
    "            writer.writerow([self.label, 'Passed By', passed_by_count, passed_by_pct])\n",
    "            writer.writerow([self.label, 'Total', total_visitors, 100.0])\n",
    "\n",
    "        print(f\"📊 Analysis saved to {filename}\")\n",
    "\n",
    "    def draw_overlays(self, frame):\n",
    "        \"\"\"\n",
    "        Draws the counting zones and enhanced count labels on the video frame.\n",
    "        \"\"\"\n",
    "        import cv2\n",
    "        # Draw main area in red\n",
    "        cv2.polylines(frame, [self.main_area], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "        \n",
    "        # Draw entrances in blue\n",
    "        for entrance in self.entrances:\n",
    "            cv2.polylines(frame, [entrance], isClosed=True, color=(255, 0, 0), thickness=2)\n",
    "        \n",
    "        count_text = f\"{self.label}: {self.person_count}\"\n",
    "        font_scale = 0.7\n",
    "        font_thickness = 2\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        \n",
    "        # Get text size for background box\n",
    "        (text_w, text_h), _ = cv2.getTextSize(count_text, font, font_scale, font_thickness)\n",
    "        \n",
    "        # Coordinates for background box\n",
    "        x, y = 50, self.text_y_position\n",
    "        cv2.rectangle(frame, (x - 5, y - text_h - 5), (x + text_w + 5, y + 5), (0, 0, 0), -1)\n",
    "        \n",
    "        # Draw white text on top\n",
    "        cv2.putText(frame, count_text, (x, y), font, font_scale, (255, 255, 255), font_thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:16:06.612720Z",
     "iopub.status.busy": "2025-08-10T20:16:06.612424Z",
     "iopub.status.idle": "2025-08-10T20:16:06.617556Z",
     "shell.execute_reply": "2025-08-10T20:16:06.616537Z",
     "shell.execute_reply.started": "2025-08-10T20:16:06.612699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Define colors and font scale based on your Desired Drawing Format ---\n",
    "box_color = (255, 0, 0)  # Blue color for the box (BGR format)\n",
    "text_color = (255, 255, 255) # White color for the text (BGR format)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.6\n",
    "font_thickness = 1\n",
    "box_thickness = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T07:22:22.684093Z",
     "iopub.status.busy": "2025-08-07T07:22:22.683787Z",
     "iopub.status.idle": "2025-08-07T07:22:22.785740Z",
     "shell.execute_reply": "2025-08-07T07:22:22.785148Z",
     "shell.execute_reply.started": "2025-08-07T07:22:22.684071Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read video and grab the first frame (for taking the store layout to define the xzones)\n",
    "cap = cv2.VideoCapture('PATH TO VIDEO')\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "# Save it as an image\n",
    "cv2.imwrite('PATH TO SAVE THE IMAGE', frame)\n",
    "print(\"Saved first frame as 'frame_0.jpg'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T20:16:10.605035Z",
     "iopub.status.busy": "2025-08-10T20:16:10.604463Z",
     "iopub.status.idle": "2025-08-10T20:16:10.612940Z",
     "shell.execute_reply": "2025-08-10T20:16:10.611995Z",
     "shell.execute_reply.started": "2025-08-10T20:16:10.605009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "####-----S2G40A------#### (NEW data, laptop section camera)\n",
    "\n",
    "# Area 1\n",
    "area_1_main_pts = np.array([[1019, 235], [658, 215], [563, 663], [1279, 606]], np.int32)\n",
    "area_1_entrance_1_pts = np.array([[665, 163], [987, 184], [1014, 231], [661, 210]], np.int32)\n",
    "area_1_entrance_2_pts = np.array([[561, 666], [1278, 609], [1272, 711], [553, 711]], np.int32)\n",
    "\n",
    "# Area 2\n",
    "area_2_main_pts = np.array([[343, 189], [629, 212], [486, 713], [1, 564]], np.int32)\n",
    "area_2_entrance_1_pts = np.array([[376, 719], [405, 695], [2, 576], [4, 714]], np.int32)\n",
    "area_2_entrance_2_pts = np.array([[345, 172], [641, 192], [632, 209], [338, 184]], np.int32)\n",
    "\n",
    "# Area 3\n",
    "area_3_main_pts = np.array([[145, 194], [247, 217], [54, 344], [2, 278]], np.int32)\n",
    "area_3_entrance_1_pts = np.array([[1, 279], [49, 345], [4, 384], [-1, 296]], np.int32)\n",
    "area_3_entrance_2_pts = np.array([[148, 193], [169, 170], [281, 196], [253, 217]], np.int32)\n",
    "\n",
    "\n",
    "\n",
    "AREA_1_TEXT = 'Track_1' \n",
    "AREA_2_TEXT = 'Track_2'\n",
    "AREA_3_TEXT = 'Track_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-10T21:15:24.096598Z",
     "iopub.status.busy": "2025-08-10T21:15:24.095886Z",
     "iopub.status.idle": "2025-08-10T21:51:50.282903Z",
     "shell.execute_reply": "2025-08-10T21:51:50.282114Z",
     "shell.execute_reply.started": "2025-08-10T21:15:24.096574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Main Loop YOLO + DEEPSORT \n",
    "\n",
    "detector = YoloDetector('yolov8l', confidence = 0.55, target_classes = [0])\n",
    "tracker = Tracker()\n",
    "# 💡 Instantiate the merger with new parameters that prioritize LOCATION\n",
    "merger = PostTracker(\n",
    "    similarity_threshold=0.62,      # Keep appearance threshold\n",
    "    max_dist_from_last_seen=150,    # Keep spatial search radius\n",
    "    time_threshold=500,              # Keep time threshold\n",
    "    motion_lambda=0.33,              #  Give 30% weight to location, 70% to appearance\n",
    "    max_cost_threshold=0.6,         #  A match is only valid if its total cost is below this value\n",
    "    feature_history_size=20,\n",
    "    debug=False                      # Set to True to see the new cost calculations\n",
    ")\n",
    "\n",
    "\n",
    "speed_factor = 1 # tried first to process one frame yes then no to make the process faster\n",
    "DETECT_EVERY = 1\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture('PATH TO VIDEO')\n",
    "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "output_fps = fps / speed_factor\n",
    "frame_count = 0\n",
    "\n",
    "video_writer = cv2.VideoWriter('PATH TO SAVE THE NEW VIDEO',\n",
    "                               cv2.VideoWriter_fourcc(*'mp4v'), output_fps, (w, h))\n",
    "\n",
    "new_total_frames = total_frames // speed_factor + (1 if total_frames % speed_factor != 0 else 0)\n",
    "pbar = tqdm(total=new_total_frames, desc=\"Processing video frames \")\n",
    "\n",
    "heatmap_generator = HeatmapGenerator(h, w, decay_factor=0.95, colormap=cv2.COLORMAP_JET)\n",
    "\n",
    "\n",
    "counter1 = CountingSystem(main_area=area_1_main_pts, entrance_areas=[area_1_entrance_1_pts , area_1_entrance_2_pts ], label = AREA_1_TEXT, position_index=0,dwell_time_seconds=5,fps=fps, debug = True)\n",
    "counter2 = CountingSystem(main_area=area_2_main_pts , entrance_areas=[area_2_entrance_1_pts , area_2_entrance_2_pts  ], label = AREA_2_TEXT, position_index=1,dwell_time_seconds=3,fps=fps, debug = True)\n",
    "counter3 = CountingSystem(main_area=area_3_main_pts  , entrance_areas=[area_3_entrance_1_pts  , area_3_entrance_2_pts   ], label = AREA_3_TEXT, position_index=2,dwell_time_seconds=3,fps=fps, debug = True)\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # 1. Run detection to get bounding boxes\n",
    "    detections, _, _ = detector.detect(frame)\n",
    "\n",
    "    # 2. Get raw tracks from DeepSORT\n",
    "    raw_tracks = tracker.track(detections, frame)\n",
    "\n",
    "    # 3. Update the post-tracker to handle ID management and re-association\n",
    "    merger.update(raw_tracks, frame_count)\n",
    "\n",
    "    # 4. Get the final, clean list of active tracks\n",
    "    final_tracks = merger.get_active_tracks()\n",
    "\n",
    "    # 5. Extract data for other modules (like counting and heatmap)\n",
    "    tracking_ids = [t['id'] for t in final_tracks]\n",
    "    boxes = [t['box'] for t in final_tracks]\n",
    "\n",
    "    # Update the counting system and heatmap generator\n",
    "    \n",
    "    counter1.update(tracking_ids, boxes, frame_count, frame)\n",
    "    counter2.update(tracking_ids, boxes, frame_count, frame)\n",
    "    counter3.update(tracking_ids, boxes, frame_count, frame)\n",
    "\n",
    "    heatmap_generator.update(boxes)\n",
    "    heatmap_frame = heatmap_generator.generate(frame)\n",
    "    \n",
    "    # --- DRAWING LOGIC ---\n",
    "    for track_info in final_tracks:\n",
    "        box = track_info['box']\n",
    "        original_id = track_info['id'] # This is the final, persistent ID\n",
    "        conf = track_info.get('conf', 0)\n",
    "        label = track_info.get('class', 'Person')\n",
    "        \n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        \n",
    "        display_label = f\"{label} {conf:.2f} ID:{original_id}\"\n",
    "        (tw, th), baseline = cv2.getTextSize(display_label, font, font_scale, font_thickness)\n",
    "        cv2.rectangle(heatmap_frame, (x1, y1), (x2, y2), box_color, box_thickness)\n",
    "        cv2.rectangle(heatmap_frame, (x1, y1 - th - baseline - 3), (x1 + tw, y1), box_color, -1)\n",
    "        cv2.putText(heatmap_frame, display_label, (x1, y1 - 5), font, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    \n",
    "    # Draw counting zones\n",
    "    counter1.draw_overlays(heatmap_frame)\n",
    "    counter2.draw_overlays(heatmap_frame)\n",
    "    counter3.draw_overlays(heatmap_frame)\n",
    "\n",
    "\n",
    "    # Write the final frame and update progress\n",
    "    video_writer.write(heatmap_frame)\n",
    "    pbar.update(1)\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "pbar.close()\n",
    "\n",
    "\n",
    "# --- NEW: Finalize and Save Dwell Times ---\n",
    "# Finalize timings for people who were still inside when the video ended\n",
    "counter1.finalize_dwell_times(frame_count)\n",
    "counter2.finalize_dwell_times(frame_count)\n",
    "counter3.finalize_dwell_times(frame_count)\n",
    "\n",
    "\n",
    "# Save all recorded dwell times to a CSV file in the output directory\n",
    "output_csv_path_area1 = f'dwell_times_{AREA_1_TEXT}.csv'\n",
    "output_csv_path_area2 = f'dwell_times_{AREA_2_TEXT}.csv'\n",
    "output_csv_path_area3 = f'dwell_times_{AREA_3_TEXT}.csv'\n",
    "\n",
    "counter1.save_to_csv(output_csv_path_area1)\n",
    "counter2.save_to_csv(output_csv_path_area2)\n",
    "counter3.save_to_csv(output_csv_path_area3)\n",
    "\n",
    "# Add this analysis section:\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"🔍 VISITOR BEHAVIOR ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Print analysis for each area\n",
    "counter1.print_analysis()\n",
    "counter2.print_analysis()\n",
    "counter3.print_analysis()\n",
    "\n",
    "# OPTIONAL: Save analysis results to CSV files\n",
    "counter1.save_analysis_to_csv(f'analysis_{AREA_1_TEXT}.csv')\n",
    "counter2.save_analysis_to_csv(f'analysis_{AREA_2_TEXT}.csv')\n",
    "counter3.save_analysis_to_csv(f'analysis_{AREA_3_TEXT}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Heatmap Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read the last frame for overlay\n",
    "# Load first frame as background\n",
    "cap = cv2.VideoCapture('PATH TO VIDEO')\n",
    "ret, store_layout_frame = cap.read()\n",
    "\n",
    "\n",
    "if not ret:\n",
    "    raise RuntimeError(\"Failed to read background frame.\")\n",
    "\n",
    "# Normalize cumulative heatmap to 0–255\n",
    "normalized_heat = cv2.normalize(heatmap_generator.cumulative_heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "normalized_heat = normalized_heat.astype(np.uint8)\n",
    "\n",
    "# Apply color map\n",
    "colored_heat = cv2.applyColorMap(normalized_heat, cv2.COLORMAP_JET)\n",
    "\n",
    "# Resize heatmap to match background frame\n",
    "if colored_heat.shape[:2] != store_layout_frame.shape[:2]:\n",
    "    colored_heat = cv2.resize(colored_heat, (store_layout_frame.shape[1], store_layout_frame.shape[0]))\n",
    "\n",
    "# Ensure 3-channel background\n",
    "if len(store_layout_frame.shape) == 2 or store_layout_frame.shape[2] == 1:\n",
    "    store_layout_frame = cv2.cvtColor(store_layout_frame, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Blend heatmap onto last frame\n",
    "final_overlay = cv2.addWeighted(store_layout_frame, 0.5, colored_heat, 0.5, 0)\n",
    "\n",
    "# ✅ Draw counter overlays (e.g., people counts, area names, etc.)\n",
    "counter1.draw_overlays(final_overlay)\n",
    "counter2.draw_overlays(final_overlay)\n",
    "counter3.draw_overlays(final_overlay)\n",
    "\n",
    "# Save results\n",
    "cv2.imwrite('final_heatmap_colored.jpg', colored_heat)\n",
    "cv2.imwrite('final_heatmap_overlay.jpg', final_overlay)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7919607,
     "sourceId": 12543969,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7952885,
     "sourceId": 12591723,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7913961,
     "sourceId": 12621418,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7953409,
     "sourceId": 12657517,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8024696,
     "sourceId": 12745505,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 410503,
     "modelInstanceId": 391817,
     "sourceId": 492940,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 410759,
     "modelInstanceId": 392082,
     "sourceId": 493265,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 419987,
     "modelInstanceId": 401995,
     "sourceId": 506313,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 427348,
     "modelInstanceId": 409490,
     "sourceId": 520210,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
